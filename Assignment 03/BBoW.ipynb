{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T01:51:52.840163Z",
     "start_time": "2021-11-15T01:50:35.280326Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 100259,
     "status": "ok",
     "timestamp": 1636909221153,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "DyXo2EBwV5ZG",
    "outputId": "b9c22f92-3987-4819-e577-0a125ce7b1ad"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import string\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "%autosave 60\n",
    "doPrint=True\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "Sets = [\"Train\", \"Test\", \"Valid\"]\n",
    "Data = {s: [] for s in Sets}\n",
    "removePunc = str.maketrans(\"\",\"\", string.punctuation)\n",
    "for s in Sets:\n",
    "    with open(f'medical_dataset/{s.lower()}.csv', encoding=\"utf8\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            T = row[\"text\"].translate(removePunc).lower().split()\n",
    "            Data[s].append({\"T\": T,\n",
    "                            \"L\": int(row[\"label\"]),\n",
    "                            \"V\": []})            \n",
    "            \n",
    "Ndic = 10000\n",
    "All=[]\n",
    "for d in Data[\"Train\"]:\n",
    "    for w in d[\"T\"]:\n",
    "        All.append(w)\n",
    "V,C = np.unique(All,return_counts=True)\n",
    "Arg = np.argsort(C)\n",
    "Dict = list(V[Arg[::-1][:Ndic]])\n",
    "Count= C[Arg][::-1][:Ndic]\n",
    "np.savetxt(\"medical_text-vocab.txt\", np.column_stack((Dict,range(1, Ndic+1), Count)),delimiter=\"\\t\",header=\"Dict, Frequency, Count\", fmt=\"%1s\")\n",
    "\n",
    "for s in Sets:\n",
    "    with open(f\"medical_text-{s.lower()}.txt\", mode='w', newline='') as Writer:\n",
    "        if doPrint:\n",
    "            W = csv.writer(Writer)\n",
    "        for d in Data[s]:\n",
    "            d[\"V\"] = np.zeros((Ndic), dtype=np.int8)\n",
    "            NW = []\n",
    "            for t in d[\"T\"]:\n",
    "                try:\n",
    "                    nw = Dict.index(t)\n",
    "                    d[\"V\"][nw] = d[\"V\"][nw]+1\n",
    "                    NW.append(nw)\n",
    "                except:\n",
    "                    pass\n",
    "            if doPrint:\n",
    "                Writer.write(\" \".join(str(np.array(NW)+1)[1:-1].split())+'\\t'+str(d[\"L\"])+'\\n')\n",
    "\n",
    "            \n",
    "def CVdata(gs):\n",
    "    means, stds, params = gs.cv_results_['mean_test_score'], gs.cv_results_['std_test_score'], gs.cv_results_['params']\n",
    "    for m, s, p in zip(means, stds, params):\n",
    "        print(f\"{m:.3f} (+/-{s*2:.3f}) for {p}\")\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T01:50:21.285923Z",
     "start_time": "2021-11-15T01:50:21.277974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2782 637 888 ... 2187 4681 1227\\t1\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(str(np.array(NW)+1)[1:-1].split())+'\\t'+str(1)+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoIB7z1qfcas"
   },
   "outputs": [],
   "source": [
    "y_t = np.array([d[\"L\"] for d in Data[\"Train\"]])-1\n",
    "X_t = np.array([d[\"V\"] for d in Data[\"Train\"]])>0\n",
    "\n",
    "y_v = np.array([d[\"L\"] for d in Data[\"Valid\"]])-1\n",
    "X_v = np.array([d[\"V\"] for d in Data[\"Valid\"]])>0\n",
    "\n",
    "X_train = np.append(X_t, X_v, axis=0)\n",
    "y_train = np.append(y_t, y_v, axis=0)\n",
    "\n",
    "y_test =  np.array([d[\"L\"] for d in Data[\"Test\"]])-1\n",
    "X_test = np.array([d[\"V\"] for d in Data[\"Test\"]])>0\n",
    "\n",
    "# tf = -np.ones_like(y_t)\n",
    "# tf = np.append(tf, np.zeros_like(y_v), axis=0)\n",
    "\n",
    "# cv = PredefinedSplit(tf)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1636881924088,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "xMsSbktbfcau",
    "outputId": "e1fdc318-e549-43ae-e3f3-479bf2fec18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in random approach: 25.59%\n",
      "Accuracy in most frequent approach (Class1): 14.18%\n"
     ]
    }
   ],
   "source": [
    "y_pred_random = np.random.randint(0,4,size=(len(y_test)))\n",
    "print(f\"Accuracy in random approach: {f1_score(y_test,y_pred_random, average='macro')*100:.2f}%\")\n",
    "\n",
    "U = np.column_stack(np.unique([d[\"L\"] for d in Data[\"Train\"] ], return_counts=True))\n",
    "y_pred_mostFreq = [max(U, key=lambda x:x[1])[0]] * len(y_test)\n",
    "print(f\"Accuracy in most frequent approach (Class{y_pred_mostFreq[0]}): {f1_score(y_test,np.array(y_pred_mostFreq)-1, average='macro')*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62659,
     "status": "ok",
     "timestamp": 1636881986722,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "aitPhG2-fcay",
    "outputId": "80cc5b43-ff21-4a06-9022-b789fbd611a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'alpha': 1.2589254117941673} with Best f1_macro of 46.51% in cross-validation.\n",
      "\n",
      "f1-macro on Train set: 51.71%\n",
      "f1-macro on Valid set: 50.55%\n",
      "f1-macro on Test  set: 45.95%\n",
      "All Parameters:\n",
      "[{'alpha': array([ 1.        ,  1.12201845,  1.25892541,  1.41253754,  1.58489319,\n",
      "        1.77827941,  1.99526231,  2.23872114,  2.51188643,  2.81838293,\n",
      "        3.16227766,  3.54813389,  3.98107171,  4.46683592,  5.01187234,\n",
      "        5.62341325,  6.30957344,  7.07945784,  7.94328235,  8.91250938,\n",
      "       10.        ])}]\n"
     ]
    }
   ],
   "source": [
    "Params_BNB = [\n",
    "    {\n",
    "        'alpha': 10**np.linspace(0,1,21)\n",
    "    }\n",
    "]\n",
    "gsBNB = GridSearchCV(BernoulliNB(), Params_BNB, scoring=scoring, cv=cv, n_jobs=-1, refit=True)\n",
    "gsBNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best hyper-parameters: {gsBNB.best_params_} with Best {scoring} of {gsBNB.best_score_*100:.2f}% in cross-validation.\\n\")\n",
    "print(f'f1-macro on Train set: {f1_score(y_t, gsBNB.predict(X_t), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Valid set: {f1_score(y_v, gsBNB.predict(X_v), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Test  set: {f1_score(y_test, gsBNB.predict(X_test), average=\"macro\")*100:.2f}%')\n",
    "\n",
    "print('All Parameters:')\n",
    "print(Params_BNB)\n",
    "# CVdata(gsBNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 761446,
     "status": "ok",
     "timestamp": 1636882748161,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "rZWpVNxJfca0",
    "outputId": "d27f88ab-83eb-42bd-a5c5-460217d7e0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 12.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 25, 'max_leaf_nodes': 75, 'min_samples_leaf': 2, 'random_state': 0} with Best f1_macro of 61.37% in cross-validation.\n",
      "\n",
      "f1-macro on Train set: 67.71%\n",
      "f1-macro on Valid set: 64.78%\n",
      "f1-macro on Test  set: 62.01%\n",
      "All Parameters:\n",
      "[{'min_samples_leaf': [2, 10, 50], 'max_leaf_nodes': [50, 75, 100], 'max_depth': [20, 25, 35, 60], 'random_state': [0]}]\n"
     ]
    }
   ],
   "source": [
    "# a\n",
    "params_DTC_noPruning = [\n",
    "    {\n",
    "        'min_samples_leaf': [2, 10, 50],  # 81\n",
    "        'max_leaf_nodes': [50, 75, 100],  # 50\n",
    "        'max_depth': [20, 25, 35, 60],  # 10\n",
    "        'random_state': [0]\n",
    "    }\n",
    "\n",
    "]\n",
    "gsDTC_noPruning = GridSearchCV(DecisionTreeClassifier(), params_DTC_noPruning, scoring=scoring, cv=cv, n_jobs=-1, refit=True, verbose=2)\n",
    "gsDTC_noPruning.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best hyper-parameters: {gsDTC_noPruning.best_params_} with Best {scoring} of {gsDTC_noPruning.best_score_*100:.2f}% in cross-validation.\\n\")\n",
    "print(f'f1-macro on Train set: {f1_score(y_t, gsDTC_noPruning.predict(X_t), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Valid set: {f1_score(y_v, gsDTC_noPruning.predict(X_v), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Test  set: {f1_score(y_test, gsDTC_noPruning.predict(X_test), average=\"macro\")*100:.2f}%')\n",
    "\n",
    "\n",
    "print('All Parameters:')\n",
    "print(params_DTC_noPruning)\n",
    "# CVdata(gsDTC_noPruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469828,
     "status": "ok",
     "timestamp": 1636883217983,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "ZJFgCZeQfca2",
    "outputId": "3ca699ff-5f20-4758-f71d-dc08427b0108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'ccp_alpha': 0.0031622776601683794, 'criterion': 'entropy', 'random_state': 0} with Best f1_macro of 59.70% in cross-validation.\n",
      "\n",
      "f1-macro on Train set: 65.79%\n",
      "f1-macro on Valid set: 64.41%\n",
      "f1-macro on Test  set: 60.79%\n",
      "All Parameters:\n",
      "[{'criterion': ['entropy'], 'random_state': [0], 'ccp_alpha': array([0.001     , 0.00125893, 0.00158489, 0.00199526, 0.00251189,\n",
      "       0.00316228, 0.00398107, 0.00501187, 0.00630957, 0.00794328,\n",
      "       0.01      , 0.01258925, 0.01584893, 0.01995262, 0.02511886,\n",
      "       0.03162278, 0.03981072, 0.05011872, 0.06309573, 0.07943282,\n",
      "       0.1       ])}]\n"
     ]
    }
   ],
   "source": [
    "params_DTC_postPruning = [\n",
    "    {\n",
    "        'criterion': ['entropy'], \n",
    "        'random_state': [0],\n",
    "        'ccp_alpha': 10**np.linspace(-3,-1,21)\n",
    "    }\n",
    "]\n",
    "gsDTC_postPruning = GridSearchCV(DecisionTreeClassifier(), params_DTC_postPruning, scoring=scoring, cv=cv, n_jobs=-1, refit=True)\n",
    "gsDTC_postPruning.fit(X_train, y_train)\n",
    "print(f\"Best hyper-parameters: {gsDTC_postPruning.best_params_} with Best {scoring} of {gsDTC_postPruning.best_score_*100:.2f}% in cross-validation.\\n\")\n",
    "print(f'f1-macro on Train set: {f1_score(y_t, gsDTC_postPruning.predict(X_t), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Valid set: {f1_score(y_v, gsDTC_postPruning.predict(X_v), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Test  set: {f1_score(y_test, gsDTC_postPruning.predict(X_test), average=\"macro\")*100:.2f}%')\n",
    "\n",
    "\n",
    "print('All Parameters:')\n",
    "print(params_DTC_postPruning)\n",
    "# CVdata(gsDTC_postPruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10190163,
     "status": "ok",
     "timestamp": 1636919674477,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "pVx4PCjvfca3",
    "outputId": "aba6c9c2-f45f-49e7-e4a2-de64b2daf0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 10 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 103.3min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 166.5min finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 1, 'penalty': 'l1', 'random_state': 0, 'solver': 'saga'} with Best f1_macro of 52.70% in cross-validation.\n",
      "\n",
      "f1-macro on Train set: 79.77%\n",
      "f1-macro on Valid set: 79.77%\n",
      "f1-macro on Test  set: 52.12%\n",
      "All Parameters:\n",
      "[{'solver': ['saga'], 'penalty': ['l1'], 'C': [1, 5, 10, 25, 50], 'random_state': [0]}, {'solver': ['saga'], 'penalty': ['l2'], 'C': [1, 5, 10, 25, 50], 'random_state': [0]}]\n"
     ]
    }
   ],
   "source": [
    "cv2 = StratifiedKFold(n_splits=8, shuffle=True, random_state=0)\n",
    "params_LR = [\n",
    "    {\n",
    "        \"solver\": ['saga'],\n",
    "        \"penalty\":['l1'],\n",
    "        \"C\": [1, 5, 10, 25, 50],\n",
    "        \"random_state\": [0]\n",
    "     },\n",
    "     {\n",
    "        \"solver\": ['saga'],\n",
    "        \"penalty\":['l2'],\n",
    "        \"C\": [1, 5, 10, 25, 50],\n",
    "        \"random_state\": [0]\n",
    "     }\n",
    "]\n",
    "gsLR = GridSearchCV(LogisticRegression(), params_LR, scoring=scoring, cv=cv2,n_jobs=-1, refit=True, verbose= 2) ######## 0.6 test 'accuracy' .8075 valid\n",
    "gsLR.fit(X_train, y_train)\n",
    "print(f\"Best hyper-parameters: {gsLR.best_params_} with Best {scoring} of {gsLR.best_score_*100:.2f}% in cross-validation.\\n\")\n",
    "print(f'f1-macro on Train set: {f1_score(y_t, gsLR.predict(X_t), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Valid set: {f1_score(y_v, gsLR.predict(X_v), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Test  set: {f1_score(y_test, gsLR.predict(X_test), average=\"macro\")*100:.2f}%')\n",
    "\n",
    "\n",
    "print('All Parameters:')\n",
    "print(params_LR)\n",
    "# CVdata(gsLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298064,
     "status": "ok",
     "timestamp": 1636899413813,
     "user": {
      "displayName": "Mostafa Dadkhah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhgPtQ3b8iJs2Zbu6qUYCqnxwLyg9t7-xBf-VAFfpA=s64",
      "userId": "02007001402843535764"
     },
     "user_tz": 300
    },
    "id": "Kh0TpQ1Ufca5",
    "outputId": "9a96b2b7-5ef4-47e9-93d3-1c4277c02f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 10, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0} with Best f1_macro of 54.73% in cross-validation.\n",
      "\n",
      "f1-macro on Train set: 79.81%\n",
      "f1-macro on Valid set: 78.66%\n",
      "f1-macro on Test  set: 51.18%\n",
      "All Parameters:\n",
      "[{'penalty': ['l2'], 'loss': ['hinge', 'squared_hinge'], 'C': [5, 10, 20, 35, 50, 75, 120], 'random_state': [0]}, {'penalty': ['l1'], 'loss': ['squared_hinge'], 'C': [5, 10, 20, 35, 50, 75, 120], 'random_state': [0]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# a\n",
    "from sklearn.svm import LinearSVC\n",
    "params_SVC = [\n",
    "     {\n",
    "        'penalty': ['l2'],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        \"C\": [5, 10, 20, 35, 50, 75, 120],\n",
    "        'random_state': [0]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1'],\n",
    "        'loss': ['squared_hinge'],\n",
    "        \"C\": [5, 10, 20, 35, 50, 75, 120],\n",
    "        'random_state': [0]\n",
    "    }]\n",
    "\n",
    "gsSVC = GridSearchCV(LinearSVC(), params_SVC, scoring=scoring, cv=cv, n_jobs=-1, refit=True, verbose= 2)\n",
    "gsSVC.fit(X_train, y_train)\n",
    "print(f\"Best hyper-parameters: {gsSVC.best_params_} with Best {scoring} of {gsSVC.best_score_*100:.2f}% in cross-validation.\\n\")\n",
    "print(f'f1-macro on Train set: {f1_score(y_t, gsSVC.predict(X_t), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Valid set: {f1_score(y_v, gsSVC.predict(X_v), average=\"macro\")*100:.2f}%')\n",
    "print(f'f1-macro on Test  set: {f1_score(y_test, gsSVC.predict(X_test), average=\"macro\")*100:.2f}%')\n",
    "\n",
    "\n",
    "print('All Parameters:')\n",
    "print(params_SVC)\n",
    "# CVdata(gsSVC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwXqRq6FqqA4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
